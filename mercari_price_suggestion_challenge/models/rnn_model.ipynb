{"cells":[{"metadata":{"_cell_guid":"7febc313-8c98-4e50-8ea3-cae09cd5b3f7","_uuid":"57406e22a3eac0606069ec582037c0c1ee3d24e4"},"cell_type":"markdown","source":"# **Import libraries and set random seed**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"db59f734-5b19-4894-9cbd-4fbe5e329836","_uuid":"52f1c5debcaacc49c722da0be1389b381e31f08c","trusted":false,"collapsed":true},"cell_type":"code","source":"import time\nt = time.time()\nimport string\nimport random\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport nltk, re, time\nfrom nltk.corpus import stopwords\n# from nltk.stem.snowball import SnowballStemmer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2b00b1cd-20f9-46d7-b83c-6dbe8a534d2a","_uuid":"8c5f2a15e4e66d57e8fb040b88ce8ea3459f5a06","trusted":false,"collapsed":true},"cell_type":"code","source":"# np_rand_seed = random.randint(0,100)\n# tf_rand_seed = random.randint(0,100)\nnp_rand_seed = 44\ntf_rand_seed = 40\nnp.random.seed(np_rand_seed)\ntf.set_random_seed(tf_rand_seed)\nprint(\"numpy random seed: \",np_rand_seed)\nprint(\"tensorflow random seed: \", tf_rand_seed)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"48b721d3-1cb0-4873-b622-6b9a3e87ee84","_uuid":"35cafed9926579335ce3e4ddc2bbfbd8a494931d"},"cell_type":"markdown","source":"# **Loading and inspecting the data**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"1b9c599c-1eef-4614-9f3e-b0b27b7a941a","_uuid":"f9e55dc8ce20453eb7dcdc8511a36f97f06f40e1","trusted":false},"cell_type":"code","source":"data = pd.read_csv(\"../input/train.tsv\", delimiter=\"\\t\")\ntest_data = pd.read_csv(\"../input/test.tsv\", delimiter=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dfb98b19-53d1-43a1-9f03-019e069d4263","_uuid":"b1b9b6485b9b5c74961ce060d14c1a08bd34c2da","trusted":false,"collapsed":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"97a580bb-c066-438b-828b-c92c57bedf10","_uuid":"f6457925df7ffc25e6081464e648892ea9f9f244","trusted":false,"collapsed":true},"cell_type":"code","source":"test_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9feef0d2-f2f2-4625-97f4-04163f2b6fc7","_uuid":"190f5a4966523d5dbbba0c5ee43e765af07ddb26","trusted":false,"collapsed":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2abcb6ed-03bc-4ce3-94bb-7eff9e0e9181","_uuid":"790d39b31cf8ec875044f9836dd643b785c2de65","trusted":false,"collapsed":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"25c86850-2072-4783-b690-b2d9680578dc","_uuid":"29c78924cdf9014bda7cc7195fcf38c0a534ab9c"},"cell_type":"markdown","source":"# **Feature Engineering**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"79d9cb35-8020-469f-a9bd-f392fd630be1","_uuid":"5a8cbdd3e87b5e8680ece39f8dbf3e89d5efc813","trusted":false},"cell_type":"code","source":"# data['brand_name'] = data['brand_name'].fillna(\"Nobrand\")\n# test_data['brand_name'] = test_data['brand_name'].fillna(\"Nobrand\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fc1f79df-dca6-45f5-8f13-87f8054b4b9c","_uuid":"4b7e39ad27501f3a6a936c5bf1b42d6d4891418d","trusted":false},"cell_type":"code","source":"# brand_name = pd.concat((data['brand_name'], test_data['brand_name']), axis=0)\n# label_encoder = LabelBinarizer()\n# label_encoder.fit(brand_name)\n# brand_label_encoded_train = label_encoder.transform(data['brand_name'])\n# brand_label_encoded_test = label_encoder.transform(test_data['brand_name'])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"ad171b47-302f-499c-bddd-2f529b961f44","_uuid":"f94ca2cdad52601fe9125c62ade502ca57846f37","trusted":false},"cell_type":"code","source":"# print(\"Shape of brand_label_encoded_train:\",brand_label_encoded_train.shape)\n# print(\"Shape of brand_label_encoded_test:\",brand_label_encoded_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"01404f7f-be02-4fe9-a647-756db9157062","_uuid":"c97ac7fc00470fb6eaa466ea2a7ee0cfc2581145","trusted":false},"cell_type":"code","source":"sw = set(stopwords.words(\"english\"))\n# stemmer = SnowballStemmer(\"english\")\ntranslator = str.maketrans(string.punctuation, ' '*len(string.punctuation))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"15ae8fb4-215b-4f03-9d04-e9ef606ae5f8","_uuid":"64cf8f4981d0550406613307ab7d82cecda7148d"},"cell_type":"markdown","source":"## **Clean Text**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"f76709e1-d2b9-427e-b10c-e1e9cf056663","_uuid":"f537881746631da26032066cc9decb0d21d7b890","trusted":false},"cell_type":"code","source":"def clean_text(text):\n    '''a function for removing punctuation'''\n    \n    text = str(text)\n    \n    # replacing the punctuations with no space,which in effect deletes the punctuation marks \n    text = text.translate(translator)\n    \n    # remove stop word\n    text = [word.lower() for word in text.split() if word.lower() not in sw]\n    text = \" \".join(text)\n    \n    # stemming\n#     text = [stemmer.stem(word) for word in text.split()]\n#     text = \" \".join(text) \n    \n    # Clean the text\n    text = re.sub(r\"<br />\", \" \", text)\n    text = re.sub(r\"[^a-z]\", \" \", text)\n    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n    text = re.sub(r\"  \", \" \", text)\n    \n    return(text)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"807287bb-f79c-4df7-bf3c-e1329d0eb75a","_uuid":"3fcbdd4d7dfe12cd22f4f219edc0b85fcca1c31a","trusted":false,"collapsed":true},"cell_type":"code","source":"t1 = time.time()\ndata['name'] = data['name'].apply(clean_text)\nprint(\"Finished cleaning the name of train set.\", \"Time needed:\", time.time()-t1)\nt2 = time.time()\ndata['category_name'] = data['category_name'].apply(clean_text)\nprint(\"Finished cleaning the catogory name of train set.\", \"Time needed:\", time.time()-t2)\nt3 = time.time()\ndata['item_description'] = data['item_description'].apply(clean_text)\nprint(\"Finished cleaning the description of train set\",\"Time needed:\", time.time()-t3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b2fad543-1816-42a3-a60d-d24b07fe2152","_uuid":"5d6fd79b162c06d8e3ce80e3954c95afdacd0108","trusted":false,"collapsed":true},"cell_type":"code","source":"t1 = time.time()\ntest_data['name'] = test_data['name'].apply(clean_text)\nprint(\"Finished cleaning the name of train set.\", \"Time needed:\", time.time()-t1)\nt2 = time.time()\ntest_data['category_name'] = test_data['category_name'].apply(clean_text)\nprint(\"Finished cleaning the catogory name of train set.\", \"Time needed:\", time.time()-t2)\nt3 = time.time()\ntest_data['item_description'] = test_data['item_description'].apply(clean_text)\nprint(\"Finished cleaning the description of train set\",\"Time needed:\", time.time()-t3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b53f7e2b-1f73-4710-bf4d-a5ba00f920c6","_uuid":"f073d361f7904d1885a057a14d2ec624bdb39137"},"cell_type":"markdown","source":"## **Tokenize Text**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"a15ac122-f30c-4129-b6ff-39aec579ef5b","_uuid":"a4a1a0b6a6df8d19e6a164b28f80615c3bbc42e4","trusted":false},"cell_type":"code","source":"all_description = pd.concat((data['item_description'], test_data['item_description']),axis=0)\ntokenizer1 = Tokenizer()\ntokenizer1.fit_on_texts(all_description)\ndel(all_description)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"519106cf-e747-4526-9e64-bbf90375e937","_uuid":"13d37ae79f4fd9ac97d9e92197a3b588220f19ed","trusted":false,"collapsed":true},"cell_type":"code","source":"description = tokenizer1.texts_to_sequences(data['item_description'])\nprint(\"train description is complete.\")\ndescription_test = tokenizer1.texts_to_sequences(test_data['item_description'])\nprint(\"test description is complete\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"518e4bb4-3c68-4e95-9bb5-5ded4922dbd7","_uuid":"89a2892d08393785c5ccc969590726bbb0b98099","trusted":false,"collapsed":true},"cell_type":"code","source":"max_length = 120\ndescription = pad_sequences(description, maxlen = max_length)\nprint(\"train decription pad is complete.\")\ndescription_test = pad_sequences(description_test, maxlen = max_length)\nprint(\"test decription pad is complete.\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"de9bb4e2-3e62-4274-a6e0-9fc162a608ed","_uuid":"a1f4c4ffcebd24402bc127aa185b3a1b4aded6fb","trusted":false},"cell_type":"code","source":"all_name = pd.concat((data['name'], test_data['name']),axis=0)\ntokenizer2 = Tokenizer()\ntokenizer2.fit_on_texts(all_name)\ndel(all_name)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"92839e4b-7087-466d-9414-322fda11d5ec","_uuid":"f8951ffee5a56bce673ffbc377fb2584d229305a","trusted":false,"collapsed":true},"cell_type":"code","source":"name = tokenizer2.texts_to_sequences(data['name'])\nprint(\"train name is complete.\")\nname_test = tokenizer2.texts_to_sequences(test_data['name'])\nprint(\"test name is complete\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"536135c0-fb76-470a-bded-a77df8aadfd2","_uuid":"d407ada543fb8728c2ab02bf6d1c84a1d0714de0","trusted":false,"collapsed":true},"cell_type":"code","source":"max_length = 15\nname = pad_sequences(name, maxlen = max_length)\nprint(\"train name pad is complete.\")\nname_test = pad_sequences(name_test, maxlen = max_length)\nprint(\"test name pad is complete.\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"72b217e3-62ff-4040-94a3-762f2fe7725e","_uuid":"90ff6b5c77bb9e5e937fdfa93f0ac78f6b1a3817","trusted":false},"cell_type":"code","source":"all_category = pd.concat((data['category_name'], test_data['category_name']),axis=0)\ntokenizer3 = Tokenizer()\ntokenizer3.fit_on_texts(all_category)\ndel(all_category)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f2efc5ec-094f-40b9-8089-c28108cf1385","_uuid":"2d7830d6ca036eb35194898cc82d64051553a21b","trusted":false,"collapsed":true},"cell_type":"code","source":"category = tokenizer3.texts_to_sequences(data['category_name'])\nprint(\"train category is complete.\")\ncategory_test = tokenizer3.texts_to_sequences(test_data['category_name'])\nprint(\"test category is complete\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0709aaf9-aba5-47ed-8dfe-8b29962c25b8","_uuid":"df42ef1e90f6903473fac732c2107364053b0278","trusted":false,"collapsed":true},"cell_type":"code","source":"max_length = 15\ncategory = pad_sequences(category, maxlen = max_length)\nprint(\"train category pad is complete.\")\ncategory_test = pad_sequences(category_test, maxlen = max_length)\nprint(\"test category pad is complete.\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"3b7c7407-d6f1-4151-adde-ef0e186aae2d","_uuid":"9e3234a2627d0bf17da9a1edb89718ec99077dbc","trusted":false},"cell_type":"code","source":"extra_data = data[['item_condition_id','shipping']].as_matrix()\nextra_data_test = test_data[['item_condition_id','shipping']].as_matrix()\nprice = data['price'].as_matrix()\ntest_id = test_data['test_id'].as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"17fff5f8-0e26-4165-b998-c77bf4a2ffca","_uuid":"32e8bf75fa9c6000223d0f085db2de018bc14ef8","trusted":false},"cell_type":"code","source":"del(data, test_data)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"08a961c0-1359-400d-83fc-5d23cfb885e4","_uuid":"ba163c36a55854db8a181a8b3de2eda0220e039c"},"cell_type":"markdown","source":"# **Create RNN for the 3 sequences**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"a0e88d66-5e8b-4769-a389-9cd7996cb301","_uuid":"664d0adc3f1c8b9237a656afed8bf5e78e735456","trusted":false},"cell_type":"code","source":"tf.reset_default_graph()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"788c6992-4071-4b46-991a-bebc9253d025","_uuid":"6daef539fd7fa8a7a309124a3637f5a0addfe9f6","trusted":false},"cell_type":"code","source":"n_words1 = len(tokenizer1.word_index)+1\nn_words2 = len(tokenizer2.word_index)+1\nn_words3 = len(tokenizer3.word_index)+1\nembed_size1 = 60\nembed_size2 = 10\nembed_size3 = 10\nn_neurons1 = 60\nn_neurons2 = 10\nn_neurons3 = 10\nname_1 = \"1\"\nname_2 = \"2\"\nname_3 = \"3\"\nn_layers = 2\nrnn_dropout = tf.placeholder(tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"721f1aec-bf90-4227-b387-c200d56c6374","_uuid":"237e9600f3fb71f8fb57957673b199bc04ce897a","trusted":false},"cell_type":"code","source":"def build_rnn(inputs, n_words, embed_size, n_neurons, n_layers, name):\n    \n    # placeholders for embeddings\n    with tf.variable_scope(\"embedding\"+name):\n        embedding = tf.Variable(tf.truncated_normal((n_words, embed_size), -0.1, 0.1))\n#         padding_zeros = tf.zeros(shape=[embed_size])\n#         embedding = tf.concat(0, [[padding_zeros], embedding])\n        embed = tf.nn.embedding_lookup(embedding, inputs, validate_indices=False)\n\n    with tf.variable_scope(\"rnn\"+name):\n        lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n                      for layer in range(n_layers)]\n        multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n        output, state = tf.nn.dynamic_rnn(multi_cell, embed, dtype=tf.float32)\n        top_layer_h_state = state[-1][1]\n        \n    return top_layer_h_state","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9d881fcf-1b0a-422c-a4d6-6bce60e85c15","_uuid":"84b41b760ca9bf107b238d76f0d8f59c958b663a","trusted":false,"collapsed":true},"cell_type":"code","source":"input1 = tf.placeholder(tf.int32, [None, None])\nrnn_output1 = build_rnn(input1, n_words1, embed_size1, n_neurons1, n_layers, name_1)\nrnn_output1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f01fb30-2ff2-45d2-b96e-ba471e3aaa5b","_uuid":"e83d684fbe3f8578ce48cafdbb50a5aa627dfbcd","trusted":false,"collapsed":true},"cell_type":"code","source":"input2 = tf.placeholder(tf.int32, [None, None])\nrnn_output2 = build_rnn(input2, n_words2, embed_size2, n_neurons2, n_layers, name_2)\nrnn_output2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"163e24b7-a964-4e7e-8ae3-a25d719cfb45","_uuid":"a289096a1b2aae26b2da535be8e026feb09d8402","trusted":false,"collapsed":true},"cell_type":"code","source":"input3 = tf.placeholder(tf.int32, [None, None])\nrnn_output3 = build_rnn(input3, n_words3, embed_size3, n_neurons3, n_layers, name_3)\nrnn_output3","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"05e3cbcf-21c7-445d-a0af-614db0048b52","_uuid":"0dfc1af8f1995b8381bbcd9992cae24e04bd6e2c","trusted":false,"collapsed":true},"cell_type":"code","source":"rnn_output_combined = tf.concat((rnn_output1, rnn_output2, rnn_output3), axis=1)\nrnn_output_combined","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34647e28-66ce-4efd-9ec8-05f614f89f53","_uuid":"523c824ad3ee73723567724b20ee183b0f4b2c6d"},"cell_type":"markdown","source":"# **Create Fully Connected Layers**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"a05f26fb-a6ed-4998-ae32-202b50408977","_uuid":"26890eda4b2cac53eef7282606a83a1b039bc9ab","trusted":false},"cell_type":"code","source":"input4 = tf.placeholder(tf.float32, [None, 2])\nprices = tf.placeholder(tf.float32, [None, 1])\nkeep_prob  = tf.placeholder(tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f06b1c89-7a26-4b9a-bb38-3f8664d837f4","_uuid":"b6eb7aa9001c9638d1342315583248b72d2be234","trusted":false},"cell_type":"code","source":"def create_weights(shape):\n    '''a function to create weight tensor'''\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n \ndef create_biases(size):\n    '''a function to create bias tensor'''\n    return tf.Variable(tf.constant(0.05, shape=[size]))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b36024dc-ba50-4372-a49b-2b43fca66e1b","_uuid":"7817f6723b1673dc1672e03ef5dc82fb17492536","trusted":false},"cell_type":"code","source":"def create_fc_layer(input,          \n                    num_inputs,    \n                    num_outputs,\n                    use_relu=True,\n                    batch_norm = True,\n                    dropout = False, \n                    keep_prob = 0.2):\n    \n    '''a function for creating fully connected layer'''\n    \n    #Let's define trainable weights and biases.\n    weights = create_weights(shape=[num_inputs, num_outputs])\n    biases = create_biases(num_outputs)\n    \n    # matrix multiplication between input and weight matrix\n    layer = tf.matmul(input, weights)\n    \n    # batch normalization if wanted\n    if batch_norm:\n        layer = tf.layers.batch_normalization(layer, training=True)\n        \n    # add the bias to the convolutional layer\n    layer += biases\n    \n    # add relu activation if wanted\n    if use_relu:\n        layer = tf.nn.relu(layer)\n        \n    # if dropout is wanted add dropout\n    if dropout:        \n        layer = tf.nn.dropout(layer, keep_prob)\n    \n    # return layer\n    return layer","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4fc76df9-93f4-4a12-bde6-4b2ae746f070","_uuid":"2ec4e00cd5673ac78841cca5d0bea7337bfc4785","trusted":false},"cell_type":"code","source":"fc_size1 = 25\nfc_size2 = 5\nfc_size3 = 5","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"90824c8c-ddc4-4142-a348-e2c119bf0bd9","_uuid":"750b6cb5f8ca373c2c94a876426f514447e3e2c5","trusted":false,"collapsed":true},"cell_type":"code","source":"fully_connected_layer1 = create_fc_layer(rnn_output_combined,\n                                         rnn_output_combined.get_shape()[1].value,\n                                         fc_size1,\n                                        use_relu=True,\n                                        batch_norm = True,\n                                        dropout =True,\n                                        keep_prob = keep_prob)\nfully_connected_layer1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8980e331-3d51-45c1-a985-8486a2957cde","_uuid":"7ad325e9b6fb602bfbdf034f852d44282b2dc492","trusted":false,"collapsed":true},"cell_type":"code","source":"fully_connected_layer2 = create_fc_layer(input4,\n                                         input4.get_shape()[1].value,\n                                         fc_size2,\n                                            use_relu=True,\n                                            batch_norm = True,\n                                            dropout =True,\n                                            keep_prob = keep_prob)\nfully_connected_layer2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"21c29e94-03c5-4b5f-acb1-aaae957b7906","_uuid":"c685a8c4c34182de6dfac647a0a3b76868106b42","trusted":false,"collapsed":true},"cell_type":"code","source":"combined_layer = tf.concat((fully_connected_layer1, fully_connected_layer2), axis=1)\ncombined_layer","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2053a366-aeff-4748-a238-c8d3c7d95620","_uuid":"0efd1647d6af260b756b78915fec3bdb3dd87abc","trusted":false,"collapsed":true},"cell_type":"code","source":"fully_connected_layer3 = create_fc_layer(combined_layer,\n                                         combined_layer.get_shape()[1].value,\n                                         fc_size3,\n                                            use_relu=True,\n                                            batch_norm = True,\n                                            dropout =True,\n                                            keep_prob = keep_prob)\nfully_connected_layer3","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a97a8167-2339-40f9-97d7-439b290ef75c","_uuid":"0dc3f8f0674308cd7db67261b7500c71efaf64ed","trusted":false,"collapsed":true},"cell_type":"code","source":"outputs = create_fc_layer(fully_connected_layer3,\n                         fc_size3,\n                         1,\n                            use_relu=False,\n                            batch_norm = False,\n                            dropout =False)\noutputs","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"40f3b631-5ae9-4b30-8f31-50cbc8c8a27d","_uuid":"78d12d7df83cc6010594643e30420a057dc56594","trusted":false},"cell_type":"code","source":"loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(tf.log(outputs+1),tf.log(prices+1)))))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"2629e150-9bea-4efd-8a90-26fe8cacab15","_uuid":"66d0a17848613bb1d536f4b20755a1f4e9a7232b","trusted":false},"cell_type":"code","source":"# learning rate of optimizer\nlearning_rate = (1e-1)*3\n# train step\ntrain_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"57b5c210-ee47-4003-9021-f6200d9d73b0","_uuid":"fbaba9dd579c24d70982312f8f88f928c8de109b"},"cell_type":"markdown","source":"# **Train model**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"04f8b09a-787d-4889-bad0-56df39dab721","_uuid":"9a9d363618a8882948b89ebb8ce7ea2fa078fa75"},"cell_type":"markdown","source":"## **Split data**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"c473d3ec-39f5-41fd-a391-669a124698bf","_uuid":"12941f383a02ec50ec13935de7bf82b5f0f8c173","trusted":false},"cell_type":"code","source":"train_indices = np.random.choice(len(price), round(len(price)*0.993), replace=False)\nvalidation_indices = np.array(list(set(range(len(price))) - set(train_indices)))\n\ndescription_train = description[train_indices]\ndescription_validation = description[validation_indices]\n\nname_train = name[train_indices]\nname_validation = name[validation_indices]\n\ncategory_train = category[train_indices]\ncategory_validation = category[validation_indices]\n\nextra_data_train = extra_data[train_indices]\nextra_data_validation = extra_data[validation_indices]\n\nprice_train = price[train_indices]\nprice_validation = price[validation_indices]\n\ndel(description, name, category, extra_data, price)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"716174aa-fd5b-41e3-a66d-50c61885896b","_uuid":"3abb1161b1054a020e9d85da6852c371dc94162a","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"Shape of description_train:\",description_train.shape)\nprint(\"Shape of description_validation:\",description_validation.shape)\nprint(\"Shape of name_train:\",name_train.shape)\nprint(\"Shape of name_validation:\",name_validation.shape)\nprint(\"Shape of category_train:\",category_train.shape)\nprint(\"Shape of category_validation:\",category_validation.shape)\nprint(\"Shape of extra_data_train:\",extra_data_train.shape)\nprint(\"Shape of extra_data_validation:\",extra_data_validation.shape)\nprint(\"Shape of price_train:\",price_train.shape)\nprint(\"Shape of price_validation:\",price_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"782a5d85-fa4f-42dd-b6a7-cac87a0c8cb8","_uuid":"624711a2acc6711c1003cd370a782bd82085960b","trusted":false},"cell_type":"code","source":"# lists to store the train loss, validation loss, validation accuracy at each iteration\ntrain_loss = []\nvalid_loss = []\n\n# batch size\nbatch_size = 100\n# max iteration\nmax_iter = 1000","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7a451c86-de33-433a-a45d-60dcd695516f","_uuid":"ba3eb9e812f16677522f5ba0e2dd1b1d219003b5"},"cell_type":"markdown","source":"## **Train and save the best model**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"85652ff1-9c42-4f5e-9c21-8336f3a2c34d","_uuid":"64ff9b17b3ac29296d088b75f852ea04a364f025","trusted":false,"collapsed":true},"cell_type":"code","source":"# create a saver object\nsaver = tf.train.Saver(max_to_keep=1)\n\n# variables to store the accuracy, loss, iteration of our best model\nbest_loss = 1000000\nbest_iteration = None\n\niteration = 0\n\n# create a graph session and optimize under it\nwith tf.Session() as sess:\n    \n    # initialize variables\n    sess.run(tf.global_variables_initializer())\n\n    # while 57 minutes have not elapsed (to finish before the kernel is killed)\n    while (time.time()-t) < 45*60:\n        \n        # break if max iteration is reached\n        if iteration >= max_iter:\n            break\n\n        # randomly choosing the indices of the batch \n        rand_index = np.random.choice(price_train.shape[0], size=batch_size)\n\n        # extract the batch image and labels\n        description_train_rand = description_train[rand_index]\n        name_train_rand = name_train[rand_index]\n        category_train_rand = category_train[rand_index]\n        extra_data_train_rand = extra_data_train[rand_index]\n        price_train_rand = price_train[rand_index]\n\n        # feed dictionary for batch\n        feed_dict_batch =  {input1: description_train_rand,\n                            input2: name_train_rand,\n                            input3: category_train_rand,\n                            input4: extra_data_train_rand,\n                            prices: np.transpose([price_train_rand]),\n                            keep_prob: 0.8}\n        # feed dictionary for train\n        feed_dict_train =  {input1: description_train_rand,\n                            input2: name_train_rand,\n                            input3: category_train_rand,\n                            input4: extra_data_train_rand,\n                            prices: np.transpose([price_train_rand]),\n                            keep_prob: 1.0}\n        # feed dictionary for validation\n        feed_dict_validation =  {input1: description_validation,\n                                input2: name_validation,\n                                input3: category_validation,\n                                input4: extra_data_validation,\n                                prices: np.transpose([price_validation]),\n                                keep_prob: 1.0}\n        \n        # execute optimization step\n        sess.run(train_step, feed_dict=feed_dict_batch)\n        \n        # calculate temporary train loss and append it to the designated list\n        temp_train_loss = loss.eval(session=sess, feed_dict=feed_dict_train)\n        train_loss.append(temp_train_loss)\n        # calculate temporary validation loss and append it to the designated list\n        temp_validation_loss = loss.eval(session=sess, feed_dict=feed_dict_validation)\n        valid_loss.append(temp_validation_loss)\n        \n        if (temp_validation_loss < best_loss):\n            best_loss = temp_validation_loss\n            best_iteration = iteration           \n            saver.save(sess, './my-model', global_step = best_iteration)\n            \n         # print metric info\n        print(\"iterations:\",iteration,\n              \"| train_loss:\", temp_train_loss,\n              \"| validation_loss:\", temp_validation_loss)\n        \n        # increment iteration\n        iteration = iteration+1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0c2ffd82-0008-4794-a871-08bd7e52d6ef","_uuid":"1ff64aaf665be9988a2d9513147deedec450bab2","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"Best loss:\", best_loss)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"733a3389-6a07-41c3-9689-f7d6a980b9fa","_uuid":"964c374a3ddc0d8ff24118903c9592d899241c29"},"cell_type":"markdown","source":"## **Compute predictions for test set**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"11b25df0-11a5-4c52-9190-12d1826bcb98","_uuid":"f735781a4a8a6e56a127695aee1d66b309ce79e9","trusted":false,"collapsed":true},"cell_type":"code","source":"with tf.Session() as sess:  \n    \n    t_start = time.time()\n    \n    # restore the best model\n    model_path = \"./\"+\"my-model-\"+str(best_iteration)\n    saver.restore(sess, model_path)\n    \n    # break the test set into k folds other wise kernel will be out of memory\n    n = len(test_id)\n    k = 100\n    step = n//k\n    \n    # array to store the prediction\n    preds = np.array([])\n\n    # iterate through each fold\n    for i in range(k):\n\n        # start and end indices of the fold\n        if i != (k-1):\n            start = (step*i)\n            end = (step*(i+1)) \n        else:\n            start = (step*i)\n            end = len(test_id)\n\n        # feed dictionary for the fold\n        feed_dict_test =  {input1: description_test[start:end],\n                            input2: name_test[start:end],\n                            input3: category_test[start:end],\n                            input4: extra_data_test[start:end],\n                            keep_prob: 1.0}\n\n        # evaluate predictions of the fold\n        fold_preds = outputs.eval(session=sess, feed_dict = feed_dict_test)\n        # append the predictions of the fold to the designated array\n        preds = np.append(preds, fold_preds)\n        \n        print(\"Computed predictions for fold\",i)\n    \n    # save the submission csv file\n    submission_path = \"./sample_submission.csv\"\n    submission = pd.DataFrame({\"test_id \": test_id, \"price\": preds})\n    submission.to_csv(submission_path, header = True, index=False)\n    \n    print(\"Time required to compute prediction:\", time.time()-t_start)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"347d467d-68cd-4183-85d9-8a017f277afc","_uuid":"64ccfb0a89550469c6fc8badea3e6ff3177bf518"},"cell_type":"markdown","source":"## **Plot of vs iterations**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"c115863b-3cbd-4e42-a8fd-8f9ffbd6b35b","_uuid":"eb060c5db9af16b25eccc577cd941bff04701c57","trusted":false,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\niterations = list(range(1,iteration+1))\nplt.plot(iterations, train_loss, label = \"train loss\")\nplt.plot(iterations, valid_loss, label = \"valid loss\")\nplt.title(\"Loss\")\nplt.xlabel(\"iter\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","version":"3.6.4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}